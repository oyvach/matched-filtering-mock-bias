{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Edits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "* Fixed a factor of 2 in nsqr in the noisevector creator function.\n",
    "* Added a prolongation factor for the noise vector creator so that a longer noise vector is made that the noise in the strain is then sampled from, to accomodate a short strain (to give the noise the correct properties)\n",
    "* Added a Tukey window to reduce spectral noise in FFT of strain/signal\n",
    "* Solved race condition in parallel code\n",
    "* Changed coalescence time parameter to better align with GW150914 observation length\n",
    "* Made code to set a chirpmass variable and to refer to this general variable later instead of 30. so that one can run for several events by adding if loops setting the event-dependent parameters.\n",
    "* Made maxmuq and dmuq variable as well, fixed from the source parameters dependent on the EVENT chosen.\n",
    "* Changed fmin to 30 Hz which seems to have been used by LIGO/Virgo (See GWTC-1)\n",
    "* Added save/load-to/from-file for chirp mass data in order for easier smaller chunk Monte Carlo\n",
    "* Removed parts of code that was not mentioned in paper and was not maintained\n",
    "\n",
    "## Second edits:\n",
    "* Made phas array global\n",
    "* Made all data being saved (each individual run separately) so that one can include the spread of the estimated parameters\n",
    "* Did the cutoff-dependency at the bottom of file more carefully (consistent grids with the above)\n",
    "* Minor adjustments\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matching Uncharged Templates to Charged Mock Data through Matched Filtering\n",
    "\n",
    "Based on code provided at LIGO open science center and theory found in Maggiore's Gravitational Waves, volume 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard python numerical analysis imports:\n",
    "import numpy as np\n",
    "from numpy.fft import fft,ifft,fftfreq\n",
    "from numpy.random import normal\n",
    "from numpy import diff, pi, sin, sqrt, conj\n",
    "#from pynverse import inversefunc\n",
    "from scipy import signal\n",
    "from scipy.optimize import fsolve\n",
    "from scipy.stats import linregress\n",
    "from functools import reduce\n",
    "#from time import time,clock\n",
    "import matplotlib.mlab as mlab\n",
    "import multiprocessing as mp\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "%matplotlib inline\n",
    "\n",
    "#Fortran made functions (f2py)\n",
    "#from fortfuncs import makeallparsfort, findsnrfort, getsnrgridfort, findrelationfort"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0: Units\n",
    "\n",
    "We'll in the following use $G= k_e = c = M_\\odot = 1$, so that everything will be dimensionless, and we have the following conversion factors:\n",
    "\n",
    "To time, multiply $ \\frac{G M_\\odot}{c^3}$.\n",
    "\n",
    "To mass, multiply $ M_\\odot$.\n",
    "\n",
    "To length, multiply $ \\frac{G M_\\odot}{c^2} $.\n",
    "\n",
    "## 0.1: Perturbation domain\n",
    "\n",
    "We will perform the analysis for charges up until our smallness parameter$ \\left[ \\epsilon \\omega^{-2/3} \\right]_{\\text{max}} = 0.1$.\n",
    "This implies that \n",
    "$$\n",
    "\\left[ \\mu \\left( \\Delta\\sigma\\right)^2\\right]_{\\text{max}} = \\frac{ 6 \\mathcal{M}^{5/4}}{25} \\left( \\frac{15}{2\\tau}\\right)^{1/4},\n",
    "$$\n",
    "and we see that the linearisation scheme allows for larger charges the smaller observing time we have (paradoxically with the early-inspiral assumption)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SWITCH\n",
    "FORT = False\n",
    "#NB Fortran version not finished and discontinued\n",
    "\n",
    "G = 6.67408e-11\n",
    "c = 2.99792458e8\n",
    "Ms = 1.989e30\n",
    "#Conversion factors\n",
    "Time = G*Ms/c**3.\n",
    "Length = G*Ms/c**2.\n",
    "\n",
    "#Parameter vector\n",
    "getpar = lambda tau0,Mc,muq,phase: np.array([tau0,Mc,muq,phase])\n",
    "#maxmuq\n",
    "getmaxmuq = lambda tau0,chirpmass: 6.*chirpmass**(5./4.)*(15./(2.*tau0))**(1./4.)/25.\n",
    "\n",
    "\n",
    "#More stuff (global)\n",
    "EVENT='LargeTau0'\n",
    "\n",
    "if EVENT=='GW151226':\n",
    "    tau0 = 1.7/Time #Convert from seconds to dimensionless units\n",
    "    chirpmass = 8.9\n",
    "    cutoff = 0.01\n",
    "    phas = np.arange(0.,-pi/5.,-pi/360.)\n",
    "    \n",
    "elif EVENT=='GW150914':\n",
    "    tau0 = 0.2/Time\n",
    "    chirpmass=28.6\n",
    "    cutoff = 0.2\n",
    "    phas = np.arange(0.,-pi/50.,-pi/3000.)\n",
    "    \n",
    "elif EVENT=='LargeTau0':\n",
    "    tau0 = 20./Time\n",
    "    chirpmass = 30.\n",
    "    cutoff = 0.002\n",
    "    phas = np.arange(0.,-2.*pi/3.,-pi/2048.)\n",
    "\n",
    "elif EVENT=='SmallChirp':\n",
    "    tau0 = 20./Time\n",
    "    chirpmass = 3.\n",
    "    cutoff = 0.0002\n",
    "    phas = np.arange(0.,-2.*pi,-pi/2048.)\n",
    "        \n",
    "\n",
    "maxmuq = getmaxmuq(tau0,chirpmass)\n",
    "dmuq = maxmuq/7.\n",
    "    \n",
    "N = 1. #N is equivalent to sqrt(S0) for the spectral function, adjust to change relative signal and noise amplitudes\n",
    "fmin = 30.*Time #Detectors sensitivity band starting at 30Hz [GWTC-1]\n",
    "fmax = 2e3*Time \n",
    "f0 = 215.*Time \n",
    "fs = 4096.*Time # From LOSC\n",
    "du = (1./fs)/(tau0)\n",
    "#From LOSC:\n",
    "NFFT = int(4*fs/Time)\n",
    "psd_window = np.blackman(NFFT)\n",
    "NOVL = int(NFFT/2)\n",
    "\n",
    "print(\"Event: \", EVENT,\"\\ndu: \",du,\"\\nmaxmuq: \",maxmuq,\" M_sun\\ntau0: \",tau0*Time,\"s\\nChirp mass: \",chirpmass, \" M_sun\",sep='')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1: Parameters/Symbols\n",
    "\n",
    "tau0 $\\sim\\tau_0$ is the initial time to coalescence. We're not interesting in varying this, so we'll assume that it can be fixed and do the analysis below for a fixed value.\n",
    "\n",
    "Mc $\\sim\\mathcal{M}^*_c$ is the generalised chirp mass.\n",
    "\n",
    "muq $\\sim\\mu (\\Delta \\sigma )^2$ is the reduced mass times the difference squared of charge to mass ratio of the 2 components.\n",
    "\n",
    "N $\\sim$ max(noise)/max(h) in the first half of inspiral in mock data\n",
    "\n",
    "And finally h $\\sim h$, is the waveform without the polarisation tensor (which is contracted with the detector tensor and just introduces a rescaling with variables that we won't vary (angles..))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2: Template/Mock Data Production"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Noise\n",
    "#f>fs, from 0601072\n",
    "def SnS0(x):\n",
    "    return x**(-4.14) - 5.*x**(-2.) + \\\n",
    "    111.*(1.-x**2. + 0.5*x**4.)/(1.+0.5*x**2.)\n",
    "\n",
    "\n",
    "\n",
    "#Some quantities // Results from analytic work\n",
    "Aw = lambda Mc: 5./( 96.*Mc**(5./3.) )\n",
    "w0 = lambda tau0,Mc: ( 3.*Aw(Mc)/(8.*tau0) )**(3./8.) #Only to first order\n",
    "epsw = lambda Mc, muq: 5.*muq/(48.*Mc**(5./3.))\n",
    "C = lambda tau0, Mc, muq: epsw(Mc,muq) * (3./14.) * w0(tau0,Mc)**(-2./3.)\n",
    "w_func = lambda u,pars: w0(pars[0],pars[1]) * u**(-3./8.) \\\n",
    "    * (1. - (3./10.) * epsw(pars[1],pars[2])*w0(pars[0],pars[1])**(-2./3.) * u**(1./4.) )\n",
    "\n",
    "#Phase\n",
    "Phi = lambda u,par: par[3] + (16./5.)*par[0]*w0(par[0],par[1]) \\\n",
    "    * ( 1. - u**(5./8.) - C(par[0],par[1],par[2])*( 1. - u**(7./8.) ) ) \n",
    "\n",
    "#Normalised amplitude, because we don't care about distance or inclination\n",
    "F = lambda u,par: w0(par[0],par[1])**(2./3.)*u**(-1./4.) \\\n",
    "    - epsw(par[1],par[2])/5.\n",
    "\n",
    "#The waveform\n",
    "h = lambda u,par: F(u,par)*np.sin(Phi(u,par))\n",
    "noh = lambda u,par: u*0.\n",
    "\n",
    "#Analytically found bias from least squares\n",
    "\n",
    "rconst = lambda c: ( 8.*(1.-c**(15./8.))*(5./13. - c + 8.*c**(13./8.)/13.)/(15.*(1.-c)) \\\n",
    "                  - 2./15. + 8.*c**(15./8.)/15. - 2.*c**(5./2.)/5.) / \\\n",
    "                ( 25./117. - c + 16.*c**(13./8.)/13. - 4.*c**(9./4.)/9. \\\n",
    "                 - (5./13. - c + 8.*c**(13./8.)/13.)**2./(1.-c) )\n",
    "sconst = lambda c: 1.-(rconst(c)*(5./13. - c + 8.*c**(13./8.)/13.) + 8.*(1.-c**(15./8.))/15.) \\\n",
    "                / (1.-c)\n",
    "\n",
    "analytbias = lambda pars,c: 1. + 8.*rconst(c)*C(pars[0],pars[1],pars[2])/5.\n",
    "\n",
    "analytphas = lambda pars,c: - 16.*pars[0]*w0(pars[0],pars[1]) \\\n",
    "    * sconst(c)*C(pars[0],pars[1],pars[2])/5.\n",
    "\n",
    "cs = np.linspace(0.,0.4)\n",
    "plt.plot(cs,rconst(cs)/rconst(0.),label='$r(c)/r_0$')\n",
    "plt.plot(cs,sconst(cs)/sconst(0.),label='$s(c)/s_0$')\n",
    "plt.xlabel('c')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "print(rconst(0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makenoisevec(Npoints):\n",
    "    dt = 1./fs\n",
    "    N = int(Npoints/2.)\n",
    "    x = np.linspace(fmin/f0,fmax/f0,N)\n",
    "    df = f0*(x[1]-x[0])\n",
    "    nullen = int(fmin/df)\n",
    "    NN = N*2 + 2*nullen + 1\n",
    "    z1 = np.zeros(N)\n",
    "    z2 = np.zeros(N)\n",
    "    for i in range(N):\n",
    "        z1[i] = normal(0,1)\n",
    "        z2[i] = normal(0,1)\n",
    "        \n",
    "    nsqr = N*dt*SnS0(x)\n",
    "    noise = np.zeros(N,np.complex)\n",
    "        \n",
    "    for i in range(N):\n",
    "        noise[i] = (z1[i]+1.j*z2[i])*sqrt(nsqr[i]/2.)\n",
    "        \n",
    "    #NB! Rearrange negative and positive frequencies into convention\n",
    "    #So that inverse Fourier is real within machine prec.\n",
    "    f = np.linspace(-fmax,fmax,NN)\n",
    "    noises = np.zeros(len(f),dtype=np.complex)\n",
    "    noises[nullen+1:nullen+1+N] = noise\n",
    "    noises[nullen+N+1:nullen+2*N+1] = conj(noise[::-1])\n",
    "    return ifft(noises)[:Npoints].real*fs\n",
    "\n",
    "#Find the power vector\n",
    "us = np.arange(1.,0.,-du)\n",
    "prolongationfac = int(20./Time / tau0)\n",
    "print(\"Noise production prolongation factor:\",prolongationfac)\n",
    "noisevec = makenoisevec(2*prolongationfac*len(us)) #Multiply with ten to get a better noise sample\n",
    "sfreq = fftfreq(len(us)*2)*fs\n",
    "print(len(noisevec), len(us), len(sfreq))\n",
    "data_psd, freqs = mlab.psd(noisevec, Fs = fs, NFFT = NFFT , window=psd_window, noverlap=NOVL)\n",
    "power_vec = np.interp(np.abs(sfreq), freqs, data_psd)\n",
    "df = abs(sfreq[1]-sfreq[0])*fs\n",
    "plt.plot(noisevec)\n",
    "plt.show()\n",
    "#plt.loglog(freqs,data_psd)\n",
    "plt.loglog(abs(sfreq)[:],power_vec,'--',label='power_vec')\n",
    "x = np.linspace(fmin/f0,fmax/f0,1000)\n",
    "plt.loglog(x*f0,SnS0(x),lw=3,label='analytical')\n",
    "plt.xlim(6e-5,2e-2)\n",
    "plt.ylim(1,3e4)\n",
    "plt.grid()\n",
    "plt.ylabel('$S_n$')\n",
    "plt.title('Noise spectral density')\n",
    "plt.legend()\n",
    "\n",
    "def mock(h,du,N,truepars,cutoff):   \n",
    "    us = np.arange(1.,0.,-du)\n",
    "    ht = np.zeros(2*len(us))\n",
    "    ind = int(len(us)*(1-cutoff))-1\n",
    "    norm = 1.\n",
    "    ht[:ind] = h(us[:ind],truepars)\n",
    "    if (h!=noh):\n",
    "        #hf = fft(ht)/fs\n",
    "        #norm = np.sqrt(abs(2.*df*(hf*conj(hf)/power_vec).sum()))\n",
    "        norm = F(0.05/(Time*truepars[0]),truepars)\n",
    "    ht = ht/norm\n",
    "    if (N>0.):\n",
    "        noisevec = makenoisevec(len(ht))[:len(ht)]\n",
    "        ht += noisevec*N\n",
    "    return ht"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutstore = cutoff\n",
    "cutoff=0.\n",
    "Nstore = N\n",
    "N= N#0.07\n",
    "truepars = getpar(tau0,chirpmass,0.,0.)\n",
    "\n",
    "\n",
    "s = mock(h,du,0.,truepars,cutoff)\n",
    "us = np.linspace(1.,0.,len(s)//2)\n",
    "us2 = np.linspace(1,-1,2*len(us))\n",
    "\n",
    "if EVENT=='GW151226':\n",
    "    start = int(len(us)/1.1)\n",
    "    stop = int(len(us2)*0.501)\n",
    "\n",
    "else:\n",
    "    start = int(len(us2)*0.45)\n",
    "    stop = int(len(us2)*0.501)\n",
    "\n",
    "fig = plt.figure()\n",
    "\n",
    "ax = fig.add_subplot(223)\n",
    "plt.plot(us2[start:stop],s[start:stop])\n",
    "#plt.axvline(x=cutoff,color='r',alpha=0.8)\n",
    "ax.invert_xaxis()\n",
    "ax.set_title('Signal')\n",
    "plt.xlabel('u')\n",
    "plt.ylabel('s')\n",
    "ax.yaxis.set_visible(False)\n",
    "\n",
    "\n",
    "start = int(len(us)/1.2)\n",
    "stop = len(us2) - int(len(us)*0.9)\n",
    "\n",
    "\n",
    "ax2 = fig.add_subplot(211)\n",
    "s = mock(h,du,N,truepars,cutoff)\n",
    "plt.plot(us2[start:stop],s[start:stop])\n",
    "ax2.invert_xaxis()\n",
    "ax2.set_title('Strain')\n",
    "plt.xlabel('u')\n",
    "plt.ylabel('s')\n",
    "ax2.yaxis.set_visible(False)\n",
    "\n",
    "\n",
    "start = int(len(us)/1.2)\n",
    "stop = int(len(us2)*0.51)\n",
    "\n",
    "pars = np.array([-tau0,30.,0.,0.])\n",
    "s = mock(noh,du,N,pars,cutoff)\n",
    "ax3 = fig.add_subplot(224)\n",
    "plt.plot(us2[start:stop],s[start:stop])\n",
    "ax3.set_title('Noise')\n",
    "ax3.invert_xaxis()\n",
    "plt.xlabel('u')\n",
    "#plt.ylabel('s')\n",
    "ax3.yaxis.set_visible(False)\n",
    "\n",
    "fig.tight_layout()\n",
    "#plt.savefig('waveformAndNoise.eps',bbox_inches='tight')\n",
    "cutoff = cutstore\n",
    "N = Nstore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3: Finding SNR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Following function taken and adapted from LOSC\n",
    "def findSNR(st,ht,cutoff):\n",
    "    dwindow =  signal.tukey(st.size, alpha=1./8)\n",
    "    \n",
    "    sf = fft(st*dwindow)/fs\n",
    "    hf = fft(ht*dwindow)/fs    \n",
    "        \n",
    "    # -- Calculate the matched filter output in the time domain:\n",
    "    # Multiply the Fourier Space template and data, and divide by the noise power in each frequency bin.\n",
    "    SNR = (2.*sf * hf.conjugate()/power_vec).sum()*df\n",
    "    # -- Normalize the matched filter output: \n",
    "    sigmasq = 2.*(hf * hf.conjugate()/power_vec).sum() * df\n",
    "    sigma = np.sqrt(np.abs(sigmasq))\n",
    "    #Return a vector (just because of the code at first being written around getting a time-series out)\n",
    "    return (( SNR/sigma )).real * np.ones(len(sf)) #This is the SNR\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4: Matched Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make template grid\n",
    "def makeallpars(tau0,chirps,muqs,phas):\n",
    "    allpars = np.zeros(len(chirps)*len(muqs)*len(phas)*4).reshape(len(chirps),len(muqs),len(phas),4)\n",
    "    for i in range(len(chirps)):\n",
    "        for j in range(len(muqs)):\n",
    "            for k in range(len(phas)):\n",
    "                allpars[i,j,k,:] = np.array([tau0,chirps[i],muqs[j],phas[k]])\n",
    "    return allpars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Just comparing SNRs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The real time-demanding code\n",
    "#Can't jit because of among other fft\n",
    "#Huge benefit possible from porting whole thing to Fortran/C then F2Py\n",
    "def getSNRgrid(allpars,truepars,du,N,cutoff):\n",
    "    st = mock(h,du,N,truepars,cutoff)\n",
    "    grid = np.zeros(reduce(lambda x,y: x*y,allpars[:,:,:,0].shape)).reshape(allpars[:,:,:,0].shape)\n",
    "    for i in range(allpars.shape[0]):\n",
    "        #print(i/allpars.shape[0],end='\\t')\n",
    "        for k in range(allpars.shape[2]):\n",
    "            for j in range(allpars.shape[1]):\n",
    "                temp = findSNR(st,mock(h,du,0.,allpars[i,j,k],cutoff),cutoff)\n",
    "                grid[i,j,k] = temp.max()\n",
    "    return grid\n",
    "\n",
    "def findBestSNR(SNRgrid,allpars):\n",
    "    maxSNR = SNRgrid.max()\n",
    "    maxSNRpars = allpars[np.where(SNRgrid==maxSNR)][0]\n",
    "    return maxSNR,maxSNRpars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "\n",
    "truepars = getpar(tau0,chirpmass,0.6,0.)\n",
    "\n",
    "chirps = np.arange(chirpmass-0.1,chirpmass+0.5,0.1) #lowres\n",
    "muqs = np.array([0.,]) #No charged templates\n",
    "allpars = makeallpars(tau0,chirps,muqs,phas)\n",
    "\n",
    "print(\"Finding SNRs...\")\n",
    "end,start = 0,0\n",
    "#start = time()\n",
    "SNRgrid = getSNRgrid(allpars,truepars,du,N,cutoff)\n",
    "maxSNR,maxSNRpars = findBestSNR(SNRgrid,allpars)\n",
    "#end = time()\n",
    "\n",
    "savedtrue = 1.*truepars #Shallow copy\n",
    "savedfalse = 1.*maxSNRpars\n",
    "\n",
    "\n",
    "print(\"Max SNR found:\\t\",maxSNR,\"\\nFor parameters (tau0,Mc,muq,phi0):\\t\",\\\n",
    "      maxSNRpars,\"\\nTrue parameters:\\t\\t\\t\",truepars, \\\n",
    "      \"\\nTotal time (s):\\t\",end-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And with that we have successfully demonstrated a large mass bias (this is in the generalised chirp mass though..). The above test-code can also be verified to give back the correct parameters when those are covered by the matched filtering search.\n",
    "\n",
    "Now we turn to look at the relationship between mass bias and $\\mu (\\Delta \\sigma)^2>0$:\n",
    "\n",
    "# 5: Chirp mass/charge relationship"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def findSNRpar(st,ht,cutoff,muq):\n",
    "    return [findSNR(st,ht,cutoff),muq]\n",
    "def getSNRgridpar(allpars,truepars,du,N,cutoff):\n",
    "    return [getSNRgrid(allpars,truepars,du,N,cutoff),truepars[2]]\n",
    "\n",
    "includeCharge = False\n",
    "if includeCharge:\n",
    "    status = 'withChargeTemplates_'\n",
    "else:\n",
    "    status = 'noChargeTemplates_'\n",
    "    \n",
    "def findRelation(dMc,dmuq,du,N,runs,cutoff):\n",
    "    chirps = np.arange(chirpmass-0.2,chirpmass+1.5,dMc)\n",
    "    muqs = np.arange(0.,.1,1.) #Not contained in matching space\n",
    "    if includeCharge:\n",
    "        muqs = np.arange(0.,maxmuq+dmuq,dmuq) #Test whether correctly predicting charge\n",
    "    allpars = makeallpars(truepars[0],chirps,muqs,phas)\n",
    "    truqs = np.arange(0.,maxmuq+dmuq,dmuq)\n",
    "    maxNSNRs = np.zeros(len(truqs)*runs).reshape(runs,len(truqs))\n",
    "    maxNPars = np.zeros(len(truqs)*4*runs).reshape(runs,len(truqs),4)\n",
    "    trueSNRs = np.zeros(len(truqs))\n",
    "    grids = []\n",
    "    trueres = []\n",
    "    gridsob = []\n",
    "    trueresob = []\n",
    "    truqgrid = np.zeros(len(truqs))\n",
    "    truqtrur = np.zeros(len(truqs))\n",
    "    pool = mp.Pool(os.cpu_count())\n",
    "    #start = time()\n",
    "    for i in range(len(truqs)):\n",
    "        #print(\"\\n muqs:\\t\",round(float(i)/len(truqs),2),end=':\\t') #Doesn't work with async\n",
    "        #print(round(float(j),1)/runs,end='\\t')\n",
    "        gridsob.append((pool.starmap_async(getSNRgridpar,[[allpars,[truepars[0],truepars[1],truqs[i],truepars[3]],du,N,cutoff],]*runs)))\n",
    "        trueresob.append(pool.starmap_async(findSNRpar,[[mock(h,du,N,[truepars[0],truepars[1],truqs[i],truepars[3]],cutoff),mock(h,du,0.,[truepars[0],truepars[1],truqs[i],truepars[3]],cutoff),cutoff,truepars[2]],]*runs))\n",
    "        #print('EST Time:\\t',(time()-start)*(len(truqs)-i-1)/(i+1)) #Doesn't work with async\n",
    "    pool.close()\n",
    "    pool.join\n",
    "    for i in range(len(truqs)):\n",
    "        grids.append(gridsob[i].get())\n",
    "        trueres.append(trueresob[i].get())\n",
    "        truqgrid[i] = grids[i][0][1]\n",
    "        truqtrur[i] = trueres[i][0][1]\n",
    "        for j in range(runs):\n",
    "            trueSNRs[i] += max(trueres[i][j][0])\n",
    "            maxNSNRs[j,i],maxNPars[j,i] = findBestSNR(grids[i][j][0],allpars)\n",
    "   \n",
    "    #sort\n",
    "    permutsgrid = np.argsort(truqgrid)\n",
    "    permutstrur = np.argsort(truqtrur)\n",
    "\n",
    "    trueSNRs = trueSNRs[permutstrur]/runs\n",
    "    maxNSNRs = maxNSNRs[:,permutsgrid]\n",
    "    maxNPars = maxNPars[:,permutsgrid]\n",
    "    \n",
    "    #Find the relative SNR\n",
    "    for i in range(runs):\n",
    "        maxNSNRs[i] = maxNSNRs[i]/trueSNRs\n",
    "    \n",
    "    \n",
    "    #Save every individual run for finding the spread of the estimated parameters\n",
    "    \n",
    "    nums=0\n",
    "    try:\n",
    "        infile = open('./chirprelationdata' + EVENT + '_N=' + str(N) + '.bin','rb')\n",
    "        nums = pickle.load(infile)\n",
    "        maxNSNRsOld = pickle.load(infile)\n",
    "        maxNParsOld = pickle.load(infile)\n",
    "        infile.close()\n",
    "        totrun = nums+runs\n",
    "        maxNSNRs2 = np.zeros(len(truqs)*totrun).reshape(totrun,len(truqs))\n",
    "        maxNPars2 = np.zeros(len(truqs)*4*totrun).reshape(totrun,len(truqs),4)\n",
    "        maxNSNRs2[:runs] = maxNSNRs[:]\n",
    "        maxNSNRs2[runs:] = maxNSNRsOld[:]\n",
    "        maxNPars2[:runs] = maxNPars[:]\n",
    "        maxNPars2[runs:] = maxNParsOld[:]\n",
    "        print('Saving together with old Monte Carlo data')\n",
    "        maxNPars = maxNPars2\n",
    "        maxNSNRs = maxNSNRs2\n",
    "        runs = totrun\n",
    "    except:\n",
    "        print('No earlier Monte Carlo found\\nSaving to new file')\n",
    "\n",
    "    outfile = open('./chirprelationdata' + EVENT + '_N=' + str(N) + '.bin','wb')\n",
    "    pickle.dump(runs,outfile)\n",
    "    pickle.dump(maxNSNRs,outfile)\n",
    "    pickle.dump(maxNPars,outfile)\n",
    "    outfile.close()\n",
    "    \n",
    "    #Return the averages\n",
    "    return maxNSNRs.sum(axis=0)/runs, maxNPars.sum(axis=0)/runs, truqs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs = 20\n",
    "\n",
    "\n",
    "maxSNRs, maxPars, truqs = findRelation(0.01,dmuq,du,N,runs,cutoff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#No parallelism beyond here\n",
    "runInTerminal = True\n",
    "if runInTerminal:\n",
    "    quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the data\n",
    "truqs = np.arange(0.,maxmuq+dmuq,dmuq)\n",
    "infile = open('./chirprelationdata' + EVENT + '_N=' + str(N) + '.bin','rb')\n",
    "runs = pickle.load(infile)\n",
    "maxNSNRs = pickle.load(infile)\n",
    "maxNPars = pickle.load(infile)\n",
    "infile.close()\n",
    "\n",
    "#averages\n",
    "maxSNRs = maxNSNRs.sum(axis=0)/runs\n",
    "maxPars = maxNPars.sum(axis=0)/runs\n",
    "\n",
    "haveSpread = True\n",
    "if haveSpread:\n",
    "    #spread\n",
    "    spreadSNRs = np.zeros(2*len(maxSNRs)).reshape(2,len(maxSNRs))\n",
    "    spreadPars = np.zeros(2*len(maxPars[0])*len(maxSNRs)).reshape(2,len(maxPars[:,0]),len(maxPars[0,:]))\n",
    "    \n",
    "    for i in range(len(maxNSNRs)):\n",
    "        spreadSNRs[0,:] = maxNSNRs.min(axis=0)\n",
    "        spreadSNRs[1,:] = maxNSNRs.max(axis=0)\n",
    "        spreadPars[0,:,:] = maxNPars.min(axis=0)\n",
    "        spreadPars[1,:,:] = maxNPars.max(axis=0)\n",
    "\n",
    "print(spreadPars.shape)\n",
    "print(spreadPars[:,:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Numbers of runs averaged over:',runs)\n",
    "print(\"Using cutoff for u<\",cutoff,\", putting ht=st=0\",sep='')\n",
    "print(\"Now with tau_0 =\",tau0*Time,\"s\")\n",
    "\n",
    "maxchirp = np.zeros(len(maxPars))\n",
    "maxphas = np.zeros(len(maxPars))\n",
    "maxmuqs = np.zeros(len(maxPars))\n",
    "for i in range(len(maxSNRs)):\n",
    "    maxchirp[i] = maxPars[i][1]\n",
    "    maxphas[i] = maxPars[i][3]\n",
    "    maxmuqs[i] = maxPars[i][2]\n",
    "    \n",
    "\n",
    "fig,ax1 = plt.subplots()\n",
    "\n",
    "\n",
    "if haveSpread:\n",
    "    ax1.fill_between(truqs,spreadSNRs[0,:],spreadSNRs[1,:],color='k',alpha=0.4)\n",
    "plt.plot(truqs,maxSNRs,'--k',lw=1.)\n",
    "#plt.plot(truqs,maxSNRs2/maxSNRs[0],lw=2., label='2')\n",
    "#plt.legend()\n",
    "#plt.grid()\n",
    "plt.ylabel(r'SNR$_{false}/$SNR$_{true}$')\n",
    "#plt.xlabel(r'$\\mu(\\Delta\\sigma)^2$')\n",
    "#plt.legend(loc='best')\n",
    "plt.grid()\n",
    "ax1.get_yaxis().get_major_formatter().set_useOffset(False)\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "\n",
    "if haveSpread:\n",
    "    ax2.fill_between(truqs,spreadPars[0,:,1]/truepars[1],spreadPars[1,:,1]/truepars[1],color='b',alpha=0.4)\n",
    "    #plt.errorbar(truqs,maxchirp/truepars[1],yerr=spreadPars[:,:,1],fmt='.')\n",
    "ax2.plot(truqs,maxchirp/truepars[1],'x',ms=9.,label='Matched Filtering')\n",
    "#plt.plot(truqs,maxPars2[:,1]/30.,lw=2.,label='Matched Filtering2')\n",
    "#a,b,c,d,e = linregress(truqs,maxPars[:,1]/truepars[1])\n",
    "#plt.plot(truqs,b+a*truqs)\n",
    "plt.grid()\n",
    "\n",
    "plt.ylabel(r'$\\mathcal{M}/\\mathcal{M}^*_{true}$')\n",
    "plt.xlabel(r'$\\mu (\\Delta\\sigma)^2/M_\\odot$')\n",
    "ax2.plot(truqs,analytbias([tau0,truepars[1],truqs,1.],cutoff),lw=1.5,label='Least square for phase')\n",
    "#plt.legend(loc='best')\n",
    "#plt.title('Averaged over '+ str(runs) + \" runs.\")\n",
    "#plt.grid()\n",
    "#plt.savefig('chirpvscharge.eps',bbox_inches='tight')\n",
    "#plt.figure()\n",
    "plt.savefig('chirp_bias_' + status + EVENT + '_N='+str(int(N)) + '_runs=' + str(runs) +'.pdf',bbox_inches='tight')\n",
    "\n",
    "plt.figure()\n",
    "plt.title(r'$\\Phi_0$')\n",
    "plt.plot(truqs,maxphas, label='Matched Filtering')\n",
    "plt.plot(truqs,((analytphas(np.array([truepars[0],truepars[1],truqs,0.]),cutoff))), '--', label='Least square for phase')\n",
    "plt.ylabel('Radians')\n",
    "plt.xlabel(r'$\\mu (\\Delta \\sigma)^2$')\n",
    "plt.grid()\n",
    "plt.savefig('initial_phase_bias_' + status + EVENT + '_N='+str(int(N)) + '_runs=' + str(runs) +'.eps',bbox_inches='tight')\n",
    "\n",
    "#plt.legend(loc='best')\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(truqs,maxmuqs)\n",
    "plt.title('charge')\n",
    "plt.savefig('charge_' + status + EVENT + '_N='+str(int(N)) + '_runs=' + str(runs) +'.eps',bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NB: Code from here on is not adapted to different choices of EVENT. You would then have to adjust the initial phase grids etc manually. Tested for EVENT=LargeTau0\n",
    "\n",
    "## 6: Cutoff Dependency of SNR & $\\mathcal{M}$ (Now comparing charged/uncharged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def findRelationCutoff(dMc, muq, cutoffs, du, N, runs):\n",
    "    chirps = np.arange(chirpmass-chirpmass/150.,chirpmass+chirpmass/30.,chirpmass/300.)\n",
    "    allpars = makeallpars(truepars[0],chirps,np.array([0,]),phas)\n",
    "\n",
    "    maxSNRs = np.zeros(len(cutoffs))\n",
    "    maxChirps = np.zeros(len(cutoffs))\n",
    "    \n",
    "    for i in range(len(cutoffs)):\n",
    "        print(\"\\n cutoff:\\t\",round(float(i)/len(cutoffs),2),end=':\\t')\n",
    "        for j in range(runs):\n",
    "            SNRgrid = getSNRgrid(allpars,truepars,du,N,cutoffs[i])\n",
    "            temp1,temp2 = findBestSNR(SNRgrid,allpars)\n",
    "            maxSNRs[i] += temp1\n",
    "            maxChirps[i] += temp2[1]\n",
    "    return maxChirps/runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Chirp dependence\n",
    "#start = time()\n",
    "cutoffs2 = np.linspace(0.,0.4,5)\n",
    "runs2 = 1\n",
    "dchirp = 0.1\n",
    "maxChirps = findRelationCutoff(dchirp,0.6,cutoffs2,du,N,runs2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SNR dependence\n",
    "truepars = 1.*savedtrue\n",
    "wrongpars = 1.*savedfalse\n",
    "\n",
    "cutoffs = np.linspace(0.,0.4,5)\n",
    "cutSNRs = np.zeros(len(cutoffs))\n",
    "runs = 10\n",
    "for i in range(len(cutoffs)):\n",
    "    temp = 0.\n",
    "    temp2 = 0.\n",
    "    st = mock(h,du,N,truepars,cutoffs[i])\n",
    "    ht = mock(h,du,0.,wrongpars,cutoffs[i])\n",
    "    for j in range(runs):\n",
    "        temp += findSNR(st,ht,cutoffs[i])\n",
    "    cutSNRs[i] = temp.max()/runs\n",
    "#end = time()\n",
    "#print(\"Time (sec):\\t\",round((end-start),2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(cutoffs,cutSNRs/cutSNRs[0])\n",
    "plt.grid()\n",
    "plt.ylabel(r'$SNR_c/SNR_{c=0}$')\n",
    "plt.xlabel(r'cutoff, $c$')\n",
    "plt.title('runs = ' +str(runs) + r',  $\\mu\\Delta \\sigma =$'+str(truepars[2]))\n",
    "plt.savefig('cutoff'+EVENT+'.png',bbox_inches='tight')\n",
    "plt.figure()\n",
    "plt.plot(cutoffs2,maxChirps/truepars[1] - 1,label='numerics')\n",
    "plt.plot(cutoffs2,8.*C(truepars[0],truepars[1],truepars[2])*rconst(cutoffs2)/5.,label='analytical')\n",
    "plt.xlabel(r'cutoff, $c$')\n",
    "plt.ylabel(r'$\\mathcal{M}/\\mathcal{M}^*_{true}-1$')\n",
    "plt.title('runs='+str(runs2)+r',  $\\mu(\\Delta\\sigma)^2=0.6$')\n",
    "plt.legend(loc='best')\n",
    "plt.savefig('chirpvscutoffswave2'+EVENT+'.png',bbox_inches='tight')\n",
    "#print(cutoffs2.shape,maxChirps.shape)\n",
    "print(\"Lower figure, muq = 0.6\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the cutoff sensitivity is negligible in the LargeTau0 scenario, but that the SNR ratio carries significant effect from the cutoff choice for the two other scenarios."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Found: \n",
    "\n",
    "LargeTau0 c$\\in(0.,0.2)$:\n",
    "* Relative SNR difference $\\sim2\\%$\n",
    "* Upper relative chirp mass difference $\\sim 0.5\\%$ (Limited by resolution)\n",
    "\n",
    "GW151226 c$\\in(0.,0.01)$:\n",
    "\n",
    "* Relative SNR difference $\\sim 20\\%$\n",
    "* Upper relative chirp mass difference $1\\%$\n",
    "\n",
    "GW150914 c$\\in(0.,0.2)$:\n",
    "* R SNR diff $\\sim 35 \\%$\n",
    "* Upper chirp diff $\\sim 3 \\%$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
